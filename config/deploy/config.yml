loss:
  loss_type: CLIPLoss
  loss_args: {}

model:
  model_type: esm_bert.EsmBertEncoder
  model_args:
    bert_model_name: prajjwal1/bert-small
    esm_model_name: facebook/esm2_t12_35M_UR50D
    num_unfrozen_bert_layers: 4
    num_unfrozen_esm_layers: 4
    init_method: xavier
    use_pretrain_weights: False
  quantize: True

optimizer:
  optimizer_type: Adam
  optimizer_args:
    desc:
      lr: 0.00005
    prot:
      lr: 0.00005
    other:
      lr: 0.001

scheduler:
  scheduler_type: ReduceLROnPlateau
  scheduler_args:
    mode: min
    factor: 0.5
    patience: 5
    threshold: 0.0001
    threshold_mode: abs

dataset:
  dataset_type: RawDescSeqDataset
  dataset_args:
    train:
      data_path: raw_data/fasta_files/latest_human_seqs.fasta
      desc_path: raw_data/descriptions/train_descriptions.json
      use_ratio: 1.0
    val:
      data_path: raw_data/fasta_files/latest_human_seqs.fasta
      desc_path: raw_data/descriptions/val_descriptions.json
      use_ratio: 1.0

dataloader:
  batch_size: 64
  collate_fn: dual_encoder_collate_fn
  collate_args:
    seq_tokenizer_args:
      pretrained_model_name_or_path: facebook/esm2_t12_35M_UR50D #facebook/esm2_t30_150M_UR50D
    desc_tokenizer_args:
      pretrained_model_name_or_path: prajjwal1/bert-small
  sampler_type: RandomSampler
  sampler_args: {}

evaluator:
  metric_type: TopKAcc
  metric_args:
    ks: [10, 20, 50]

logger:
  logger_type: stdout
  logger_args: {}

save_model:
  save_model: True
  mode: min
  monitor: val/epoch_loss
  save_model_dir: trained_models/esm_bert #esm25m_4layer_smallbert
  identifier: xavier_esm25m_3layer_smallbert

trainer:
  trainer_type: clip_trainer.CLIPTrainer
  trainer_args:
    max_epochs: 50
    device: "cuda"
    enable_progress_bar: False
    use_amp: false
    resume_from_checkpoint: trained_models/2025-01-05-16-06-30-4x_mixed_data_esm25m_smallbert/best_state.pt
    device: cpu
